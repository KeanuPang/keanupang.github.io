<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>unit-test on Living today for tomorrow</title><link>https://keanupang.github.io/tags/unit-test/</link><description>Recent content in unit-test on Living today for tomorrow</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 02 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://keanupang.github.io/tags/unit-test/index.xml" rel="self" type="application/rss+xml"/><item><title>Snapshot Testing 的調整經驗筆記</title><link>https://keanupang.github.io/posts/ios-snapshot-testing-note/</link><pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate><guid>https://keanupang.github.io/posts/ios-snapshot-testing-note/</guid><description>我們的專案已經有 816 snapshot tests 並且有 600 張 snapshots，對專案的 coverage 約 47%，對產品的品質信心算是滿足夠的。
常被抱怨的點是在 CI 上跑 unit test 的時間太久，以專案 800 多個 snapshot tests 來說需要花上 15 mins 才能跑完，有時候開的 PR 一多幾乎都是在等待 unit test 跑結束，反而有點浪費在等待，目前只能採取折衷的作法，在特定的 branch 才啟動 unit test。
另外遇到的問題是不同機器配上對應的模擬器有時候會發生圖片”看起來”是一樣內容，但檔案大小卻差了幾個 bytes，所以程式比對圖片就直接認定 assert failed。原因是畫面在截取的當下可能仍會因為動畫等視覺效果，而造成產生的 snapshot 有些微色彩的差異。
這類問題的解法目前是走 duplicate image detection 的做法，也就是算出 snapshot 對應的 hash 值，然後將兩張圖片的 hash 根據 Hamming distance 來評估是不是一樣的圖片。
本來是在這邊 GitHub – benhoyt/dhash 看到這個，查了一下大概就是這幾種 hash 方法的比較，來源是 GitHub – ameingast/cocoaimagehashing 這裡：
Name Performance Quality aHash good bad dHash excellent good pHash bad excellent 其實滿推崇 pHash 的方法，看 別人分享 iOS 上測試的過程 具有很多優勢；但因為 dHash 實作上相對容易，也滿多實作的作品可以參考。自己參考的實作是這兩篇：</description></item></channel></rss>